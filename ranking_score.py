import pandas as pd
import requests
from bs4 import BeautifulSoup
import pandas_ta as ta
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from io import StringIO
import os
import concurrent.futures
import time

# safe_float í•¨ìˆ˜ëŠ” ì´ íŒŒì¼ì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ ì—¬ê¸°ì— ì •ì˜
def safe_float(value):
    try:
        # ì½¤ë§ˆ ì œê±° í›„ float ë³€í™˜
        return float(str(value).replace(",", ""))
    except (ValueError, AttributeError):
        return np.nan

# âœ… ì¢…ëª© ì½”ë“œ ë§¤í•‘ìš© í•¨ìˆ˜
def fetch_code_map():
    url = "https://kind.krx.co.kr/corpgeneral/corpList.do?method=download"
    try:
        df = pd.read_html(url, encoding='euc-kr')[0]
        df = df[['íšŒì‚¬ëª…', 'ì¢…ëª©ì½”ë“œ']]
        df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].apply(lambda x: f"{x:06d}")
        return dict(zip(df['íšŒì‚¬ëª…'], df['ì¢…ëª©ì½”ë“œ']))
    except Exception as e:
        print(f"âš ï¸ KRX ì¢…ëª© ì½”ë“œ ë§¤í•‘ ì‹¤íŒ¨: {e}")
        return {}

# âœ… ê¸°ìˆ ì  ì§€í‘œìš© ì‹¤ì œ ì¢…ê°€ ì‹œí€€ìŠ¤, ê±°ë˜ëŸ‰ ê°€ì ¸ì˜¤ê¸°
def fetch_real_close_prices(code, days=120):
    sise_url = f"https://finance.naver.com/item/sise_day.nhn?code={code}"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    }
    
    close_prices = pd.Series([], dtype=float)
    volumes = pd.Series([], dtype=float)

    # ì¢…ê°€ ë° ê±°ë˜ëŸ‰ ë°ì´í„° í¬ë¡¤ë§
    dfs_sise = []
    for page in range(1, 10):
        pg_url = f"{sise_url}&page={page}"
        try:
            res = requests.get(pg_url, headers=headers, timeout=10)
            if res.status_code != 200:
                break
            df = pd.read_html(StringIO(res.text))[0]
            if df.empty:
                break
            dfs_sise.append(df)
        except (requests.exceptions.RequestException, ValueError):
            break

    if dfs_sise:
        df_sise = pd.concat(dfs_sise, ignore_index=True)
        df_sise = df_sise.dropna()
        df_sise['ë‚ ì§œ'] = pd.to_datetime(df_sise['ë‚ ì§œ'])
        df_sise = df_sise.sort_values(by='ë‚ ì§œ').reset_index(drop=True)
        close_prices = df_sise['ì¢…ê°€'].astype(float).tail(days)
        volumes = df_sise['ê±°ë˜ëŸ‰'].astype(float).tail(days)
    
    return close_prices, volumes


# âœ… ì‹œì¥ë³„ ì£¼ì‹ ëª©ë¡ ë° ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ (ì™¸êµ­ì¸ë¹„ìœ¨ ì»¬ëŸ¼ ì¶”ê°€)
def fetch_stock_list(market='kospi', pages=10):
    base_url = {
        'kospi': 'https://finance.naver.com/sise/sise_market_sum.nhn?sosok=0&page=',
        'kosdaq': 'https://finance.naver.com/sise/sise_market_sum.nhn?sosok=1&page='
    }[market]

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    }
    dfs = []
    required_cols = ['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'PER', 'ROE'] # í•„ìˆ˜ ì»¬ëŸ¼
    foreign_rate_col_candidates = ['ì™¸êµ­ì¸ë¹„ìœ¨', 'ì™¸êµ­ì¸ë¹„ìœ¨(%)', 'ì™¸êµ­ì¸ë³´ìœ ìœ¨'] # ì™¸êµ­ì¸ ë¹„ìœ¨ ì»¬ëŸ¼ í›„ë³´ë“¤

    for page in range(1, pages + 1):
        url = base_url + str(page)
        print(f"--- ğŸŒ {market.upper()} í˜ì´ì§€ {page} í¬ë¡¤ë§ ì‹œë„ ì¤‘ ---") # ë””ë²„ê¹…ìš© print
        try:
            res = requests.get(url, headers=headers, timeout=15)
            if res.status_code != 200:
                print(f"âš ï¸ í˜ì´ì§€ {page} ì ‘ì† ì‹¤íŒ¨: Status Code {res.status_code}")
                continue

            soup = BeautifulSoup(res.text, "html.parser")
            table_selector = "table.type_2"
            table = soup.select_one(table_selector)
            if not table:
                print(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ '{table_selector}' í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            tables_from_html = pd.read_html(StringIO(res.text))
            df_page = pd.DataFrame()
            found_target_table = False

            for temp_df in tables_from_html:
                has_all_required_base_cols = all(col in temp_df.columns for col in required_cols)
                has_foreign_rate_col = any(col in temp_df.columns for col in foreign_rate_col_candidates)
                
                if has_all_required_base_cols and has_foreign_rate_col:
                    df_page = temp_df
                    found_target_table = True
                    break
            
            if not found_target_table:
                print(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ í•„ìˆ˜ ì»¬ëŸ¼ì„ í¬í•¨í•˜ëŠ” í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue 

            foreign_rate_col_name_found = None
            for col_candidate in foreign_rate_col_candidates:
                if col_candidate in df_page.columns:
                    foreign_rate_col_name_found = col_candidate
                    break
            
            if not foreign_rate_col_name_found:
                print(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ ì™¸êµ­ì¸ë¹„ìœ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (í›„ë³´: {foreign_rate_col_candidates}, ì‹¤ì œ: {df_page.columns.tolist()})")
                continue 

            df_page = df_page.rename(columns={foreign_rate_col_name_found: 'ì™¸êµ­ì¸ë¹„ìœ¨'})
            
            final_cols = required_cols + ['ì™¸êµ­ì¸ë¹„ìœ¨']

            if not all(col in df_page.columns for col in final_cols):
                missing_cols = [col for col in final_cols if col not in df_page.columns]
                print(f"âš ï¸ í˜ì´ì§€ {page} - ìµœì¢… ì»¬ëŸ¼ ì„ íƒ í›„ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_cols}. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            df_page = df_page[final_cols].copy() 

            # â­ ìˆ˜ì •ëœ ë¶€ë¶„: safe_floatë¥¼ ë¨¼ì € ì ìš©í•˜ì—¬ floatìœ¼ë¡œ ë³€í™˜
            df_page['í˜„ì¬ê°€'] = df_page['í˜„ì¬ê°€'].apply(safe_float)
            df_page['PER'] = df_page['PER'].apply(safe_float)
            df_page['ROE'] = df_page['ROE'].apply(safe_float)
            df_page['ì™¸êµ­ì¸ë¹„ìœ¨'] = df_page['ì™¸êµ­ì¸ë¹„ìœ¨'].apply(safe_float)

            # NaN ê°’ ì œê±° (ì—¬ê¸°ì„œ ì œê±°í•˜ë©´ KeyErrorê°€ ë‚˜ì§€ ì•Šë„ë¡ ì´ë¯¸ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„)
            # ìˆ«ì ë³€í™˜ ì˜¤ë¥˜ê°€ ì•„ë‹ˆë¼ ë°ì´í„° ìì²´ì— ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°ë¥¼ ìœ„í•´ ë‹¤ì‹œ í•œë²ˆ dropna
            df_page = df_page.dropna(subset=final_cols)
            
            # â­ ìˆ˜ì •ëœ ë¶€ë¶„: í˜„ì¬ê°€ëŠ” ì •ìˆ˜í˜•ì´ë¯€ë¡œ ë‹¤ì‹œ intë¡œ ë³€í™˜ (NaN ê°’ ì œê±° í›„)
            df_page['í˜„ì¬ê°€'] = df_page['í˜„ì¬ê°€'].astype(int)

            if df_page.empty:
                print(f"âš ï¸ í˜ì´ì§€ {page} - NaN ê°’ ì œê±° í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            dfs.append(df_page)
            print(f"âœ… í˜ì´ì§€ {page}ì—ì„œ {len(df_page)}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ.") # ì„±ê³µ ì‹œ ì¶œë ¥

        except (requests.exceptions.RequestException, ValueError, IndexError, KeyError, TypeError) as e:
            print(f"âŒ ì‹œì¥ ëª©ë¡ í¬ë¡¤ë§ ì˜¤ë¥˜ (í˜ì´ì§€ {page}, ìƒì„¸: {e})")
            continue 

    if not dfs:
        print("âŒ ì‹œì¥ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¹ˆ DataFrame ë°˜í™˜.")
        return pd.DataFrame()

    full_df = pd.concat(dfs, ignore_index=True)
    full_df = full_df.dropna(subset=required_cols + ['ì™¸êµ­ì¸ë¹„ìœ¨']) 
    
    return full_df.reset_index(drop=True)


# ê° ì¢…ëª©ì„ ì²˜ë¦¬í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
def _process_single_stock(stock_info, code_map):
    name = stock_info['ì¢…ëª©ëª…']
    code = code_map.get(name)
    if not code:
        return None

    try:
        close_prices, volumes = fetch_real_close_prices(code) 
        
        current_foreign_rate = stock_info.get('ì™¸êµ­ì¸ë¹„ìœ¨', np.nan) 
        
        if len(close_prices) < 60 or len(volumes) < 60: 
            return None

        rsi_series = ta.rsi(close_prices, length=14)
        macd_df = ta.macd(close_prices)
        bb_df = ta.bbands(close_prices)

        if rsi_series.empty or macd_df.empty or bb_df.empty:
             return None

        current_rsi = rsi_series.iloc[-1]
        prev_rsi = rsi_series.iloc[-2] if len(rsi_series) >= 2 else np.nan
        macd_line = macd_df["MACD_12_26_9"].iloc[-1]
        signal_line = macd_df["MACDs_12_26_9"].iloc[-1]
        prev_macd_line = macd_df["MACD_12_26_9"].iloc[-2] if len(macd_df) >= 2 else np.nan
        prev_signal_line = macd_df["MACDs_12_26_9"].iloc[-2] if len(macd_df) >= 2 else np.nan
        percent_b = bb_df["BBP_5_2.0"].iloc[-1]
        bbl = bb_df["BBL_5_2.0"].iloc[-1]
        current_close_price = close_prices.iloc[-1]
        current_volume = volumes.iloc[-1]
        
        avg_volume_20_days = volumes.rolling(window=20).mean().iloc[-1] if len(volumes) >= 20 else np.nan

        foreign_ownership_change = np.nan 
        
        is_foreign_inflow = True if pd.notna(current_foreign_rate) and current_foreign_rate >= 5 else False 

        per = stock_info["PER"] if pd.notna(stock_info["PER"]) and stock_info["PER"] > 0 else 1000
        roe = stock_info["ROE"] if pd.notna(stock_info["ROE"]) else 0

        is_rsi_recovery = False
        if pd.notna(prev_rsi) and prev_rsi < 30 and current_rsi >= 30:
            is_rsi_recovery = True

        is_macd_golden_cross = False
        if pd.notna(prev_macd_line) and pd.notna(prev_signal_line) and \
           macd_line > signal_line and prev_macd_line <= prev_signal_line:
            is_macd_golden_cross = True
        
        is_bb_lower_band_recovery = False
        if len(close_prices) >= 10 and not bb_df["BBL_5_2.0"].iloc[-10:].isnull().any():
            was_below_bbl = any(close_prices.iloc[-10:-1] < bb_df["BBL_5_2.0"].iloc[-10:-1])
            is_above_bbl_now = current_close_price > bbl
            if was_below_bbl and is_above_bbl_now:
                is_bb_lower_band_recovery = True

        is_volume_spike = False
        if pd.notna(avg_volume_20_days) and current_volume > (avg_volume_20_days * 2):
            is_volume_spike = True
        
        is_foreign_inflow = True if pd.notna(current_foreign_rate) and current_foreign_rate >= 5 else False 

        surge_score = sum([
            is_rsi_recovery,
            is_macd_golden_cross,
            is_bb_lower_band_recovery,
            is_volume_spike,
            is_foreign_inflow 
        ])
        surge_signal_text = ", ".join([
            s for s, flag in {
                "RSI íšŒë³µ": is_rsi_recovery,
                "MACD GC": is_macd_golden_cross,
                "BB íšŒë³µ": is_bb_lower_band_recovery,
                "ê±°ë˜ëŸ‰ ê¸‰ì¦": is_volume_spike,
                "ì™¸êµ­ì¸ ìˆ˜ê¸‰(ë¹„ìœ¨ ë†’ìŒ)": is_foreign_inflow 
            }.items() if flag
        ])
        if not surge_signal_text:
            surge_signal_text = "ì—†ìŒ"

        per_score = min(1/per * 100, 1)
        roe_score = roe / 20
        rsi_score = 1 if current_rsi < 30 else 0 if current_rsi > 70 else 0.5
        macd_score = 1 if is_macd_golden_cross else 0
        bb_score = percent_b
        foreign_score = 1 if is_foreign_inflow else 0 

        raw_metrics = [per_score, roe_score, rsi_score, macd_score, bb_score, foreign_score]

        naver_stock_link = f"https://finance.naver.com/item/main.naver?code={code}"

        return {
            "ì¢…ëª©ëª…": name,
            "í˜„ì¬ê°€": stock_info["í˜„ì¬ê°€"],
            "PER": round(per, 2),
            "ROE": round(roe, 2),
            "RSI": round(current_rsi, 2),
            "MACD_Line": round(macd_line, 2),
            "Signal_Line": round(signal_line, 2),
            "BB_Percent_B": round(percent_b, 2),
            "í˜„ì¬_ê±°ë˜ëŸ‰": int(current_volume),
            "20ì¼_í‰ê· _ê±°ë˜ëŸ‰": int(avg_volume_20_days) if pd.notna(avg_volume_20_days) else 0,
            "ì™¸êµ­ì¸_í˜„ì¬_ë³´ìœ ìœ¨": round(current_foreign_rate, 2) if pd.notna(current_foreign_rate) else np.nan,
            "ì™¸êµ­ì¸_ë³´ìœ ìœ¨_ë³€í™”": np.nan, 
            "ê¸‰ë“±_ì ìˆ˜": surge_score,
            "ê¸‰ë“±_ì‹œê·¸ë„": surge_signal_text,
            "ë„¤ì´ë²„_ì£¼ì‹_ë§í¬": naver_stock_link,
            "_raw_metrics": raw_metrics
        }

    except Exception as e:
        print(f"âš ï¸ ì¢…ëª© '{name}' (ì½”ë“œ: {code}) ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# âœ… ì¢…ëª© ì ìˆ˜ ê³„ì‚° ë° ê¸‰ë“± í•„í„° í¬í•¨ (ë³‘ë ¬ ì²˜ë¦¬ ì ìš©) (ë³€ê²½ ì—†ìŒ)
def rank_stocks(df, code_map):
    all_stock_data = []
    
    max_workers = os.cpu_count() * 2 if os.cpu_count() else 10

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(_process_single_stock, row.to_dict(), code_map): row['ì¢…ëª©ëª…'] for idx, row in df.iterrows()}
        
        processed_count = 0
        total_stocks = len(futures)

        for future in concurrent.futures.as_completed(futures):
            processed_count += 1
            stock_name = futures[future]
            try:
                result = future.result()
                if result:
                    all_stock_data.append(result)
            except Exception as exc:
                print(f"âš ï¸ ì¢…ëª© '{stock_name}' ìµœì¢… ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {exc}")
            
            if processed_count % 100 == 0 or processed_count == total_stocks:
                print(f"  {processed_count}/{total_stocks} ì¢…ëª© ì²˜ë¦¬ ì™„ë£Œ ({stock_name} ì²˜ë¦¬ë¨)")

    if not all_stock_data:
        print("âŒ rank_stocks: ìœ íš¨í•œ ë°ì´í„°ë¥¼ ê°€ì§„ ì¢…ëª©ì´ ì—†ì–´ ìµœì¢… DataFrameì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. JSON íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    try:
        metrics_array = np.array([item["_raw_metrics"] for item in all_stock_data])
        scaler = MinMaxScaler()
        normed = scaler.fit_transform(metrics_array)
        
        weights = np.array([0.2, 0.2, 0.15, 0.15, 0.1, 0.2])
        final_scores = normed @ weights

        for i, score in enumerate(final_scores):
            all_stock_data[i]['score'] = round(score, 4)
            del all_stock_data[i]['_raw_metrics']
    except Exception as e:
        print(f"âŒ ì ìˆ˜ ì •ê·œí™” ë° ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()


    full_df = pd.DataFrame(all_stock_data).sort_values(by="score", ascending=False).reset_index(drop=True)

    financial_df = full_df[
        (full_df['PER'] < 30) & (full_df['ROE'] > 5)
    ].sort_values(by=["ROE", "PER", "score"], ascending=[False, True, False]).head(50)

    surge_df = full_df[full_df['ê¸‰ë“±_ì ìˆ˜'] >= 2].sort_values(by="ê¸‰ë“±_ì ìˆ˜", ascending=False).reset_index(drop=True)

    return full_df, financial_df, surge_df


# âœ… ì‹œì¥ë³„ ì‹¤í–‰ (ë³€ê²½ ì—†ìŒ)
def run_for_market(market):
    print(f"\n--- ğŸ“Š {market.upper()} ì‹œì¥ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘ ---")
    start_time = time.time()
    
    df = fetch_stock_list(market, pages=20) 
    print(f"âœ… {len(df)}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ.")
    if df.empty:
        print(f"âš ï¸ {market.upper()} ì‹œì¥ì— ìœ íš¨í•œ ì¢…ëª©ì´ ì—†ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print("ğŸ—ºï¸ ì¢…ëª© ì½”ë“œ ë§¤í•‘ ì¤‘...")
    code_map = fetch_code_map()
    if not code_map:
        print(f"âš ï¸ ì¢…ëª© ì½”ë“œ ë§¤í•‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print("â³ ì¢…ëª© ì ìˆ˜ ê³„ì‚° ì¤‘ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥´ê²Œ ì§„í–‰ë©ë‹ˆë‹¤)...")
    full, financial, surge = rank_stocks(df, code_map)

    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"\nâœ¨ {market.upper()} ì‹œì¥ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ! (ì´ {elapsed_time:.2f}ì´ˆ ì†Œìš”)")

    print(f"\n--- ğŸ† {market.upper()} ì „ì²´ ìƒìœ„ ì¢…í•© ë­í‚¹ ---")
    print(full[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'score', 'ë„¤ì´ë²„_ì£¼ì‹_ë§í¬']].head(20) if not full.empty else "ì—†ìŒ")

    print(f"\n--- ğŸ’° {market.upper()} ì¬ë¬´ ê±´ì „ì„± ìš°ìˆ˜ ì¢…ëª© (PER 30 ì´í•˜, ROE 5 ì´ìƒ ê¸°ì¤€) ---")
    print(financial[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'PER', 'ROE', 'score', 'ë„¤ì´ë²„_ì£¼ì‹_ë§í¬']].head(20) if not financial.empty else "ì—†ìŒ")

    print(f"\n--- ğŸ”¥ {market.upper()} ê¸‰ë“± ê°€ëŠ¥ì„± ì¢…ëª© (ê¸‰ë“±_ì ìˆ˜ â‰¥ 2) ---")
    print(surge[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ê¸‰ë“±_ì ìˆ˜', 'ê¸‰ë“±_ì‹œê·¸ë„', 'í˜„ì¬_ê±°ë˜ëŸ‰', '20ì¼_í‰ê· _ê±°ë˜ëŸ‰', 'ì™¸êµ­ì¸_í˜„ì¬_ë³´ìœ ìœ¨', 'score', 'ë„¤ì´ë²„_ì£¼ì‹_ë§í¬']].head(20) if not surge.empty else "ì—†ìŒ") 

    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)

    if not full.empty:
        full.to_json(f"{output_dir}/{market}_ranked_stocks_all.json", orient="records", force_ascii=False, indent=2)
        print(f"\nğŸ“ {output_dir}/{market}_ranked_stocks_all.json ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âš ï¸ {market.upper()} ì „ì²´ ë­í‚¹ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ JSON íŒŒì¼ ì €ì¥ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    if not financial.empty:
        financial.to_json(f"{output_dir}/{market}_ranked_stocks_financial_healthy.json", orient="records", force_ascii=False, indent=2)
        print(f"ğŸ“ {output_dir}/{market}_ranked_stocks_financial_healthy.json ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âš ï¸ {market.upper()} ì¬ë¬´ ê±´ì „ì„± ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ JSON íŒŒì¼ ì €ì¥ ê±´ë„ˆëœë‹ˆë‹¤.")

    if not surge.empty:
        surge.to_json(f"{output_dir}/{market}_ranked_stocks_potential_surge.json", orient="records", force_ascii=False, indent=2)
        print(f"ğŸ“ {output_dir}/{market}_ranked_stocks_potential_surge.json ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âš ï¸ {market.upper()} ê¸‰ë“± ê°€ëŠ¥ì„± ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ JSON íŒŒì¼ ì €ì¥ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    print(f"\n--- {market.upper()} ì‹œì¥ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ---\n")


# âœ… ì‹¤í–‰
if __name__ == "__main__":
    run_for_market("kospi")
    run_for_market("kosdaq")