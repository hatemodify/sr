import pandas as pd
import requests
from bs4 import BeautifulSoup
import pandas_ta as ta
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from io import StringIO
import os
import concurrent.futures

import time

# safe_float í•¨ìˆ˜ëŠ” ì´ íŒŒì¼ì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ ì—¬ê¸°ì— ì •ì˜
def safe_float(value):
    try:
        # ì½¤ë§ˆ ì œê±° í›„ float ë³€í™˜
        return float(str(value).replace(",", ""))
    except (ValueError, AttributeError):
        return np.nan

# âœ… ì¢…ëª© ì½”ë“œ ë§¤í•‘ìš© í•¨ìˆ˜
def fetch_code_map():
    url = "https://kind.krx.co.kr/corpgeneral/corpList.do?method=download"
    try:
        df = pd.read_html(url, encoding='euc-kr')[0]
        df = df[['íšŒì‚¬ëª…', 'ì¢…ëª©ì½”ë“œ']]
        df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].apply(lambda x: f"{x:06d}")
        return dict(zip(df['íšŒì‚¬ëª…'], df['ì¢…ëª©ì½”ë“œ']))
    except Exception as e:
        print(f"âš ï¸ KRX ì¢…ëª© ì½”ë“œ ë§¤í•‘ ì‹¤íŒ¨: {e}")
        return {}

# âœ… ê¸°ìˆ ì  ì§€í‘œìš© ì‹¤ì œ ì¢…ê°€ ì‹œí€€ìŠ¤, ê±°ë˜ëŸ‰ ê°€ì ¸ì˜¤ê¸°
def fetch_real_close_prices(code, days=120):
    sise_url = f"https://finance.naver.com/item/sise_day.nhn?code={code}"

    # â­ ìµœì‹  User-Agentë¡œ ì—…ë°ì´íŠ¸
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    }
    
    close_prices = pd.Series([], dtype=float)
    volumes = pd.Series([], dtype=float)

    dfs_sise = []
    for page in range(1, 10): # ìµœëŒ€ 9í˜ì´ì§€ê¹Œì§€ë§Œ ì‹œë„ (ëŒ€ëµ 1ë…„ì¹˜ ë°ì´í„°)
        pg_url = f"{sise_url}&page={page}"
        try:
            res = requests.get(pg_url, headers=headers, timeout=10)
            if res.status_code != 200:
                break
            
            # â­ HTML ë‚´ìš©ì„ StringIOë¡œ ì „ë‹¬í•˜ê¸° ì „ì— ìœ íš¨ì„± ê²€ì‚¬
            if "ìº¡ì°¨" in res.text or "ì°¨ë‹¨" in res.text: # ê°„ë‹¨í•œ ìº¡ì°¨/ì°¨ë‹¨ ë©”ì‹œì§€ í™•ì¸
                print(f"âš ï¸ ê²½ê³ : {code} ì¢…ëª© ì‹œì„¸ í¬ë¡¤ë§ ì¤‘ ìº¡ì°¨/IP ì°¨ë‹¨ ê°ì§€. í˜ì´ì§€: {page}")
                break

            df = pd.read_html(StringIO(res.text))[0]
            if df.empty or 'ë‚ ì§œ' not in df.columns: # 'ë‚ ì§œ' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìœ íš¨í•œ í…Œì´ë¸”ì´ ì•„ë‹˜
                break
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ë°ì´í„° ì •ë¦¬
            df = df[['ë‚ ì§œ', 'ì¢…ê°€', 'ê±°ë˜ëŸ‰']].dropna()
            df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
            df = df.sort_values(by='ë‚ ì§œ').reset_index(drop=True)
            dfs_sise.append(df)
            
            time.sleep(0.1) # ìš”ì²­ ê°„ ì§§ì€ ë”œë ˆì´ ì¶”ê°€
        except (requests.exceptions.RequestException, ValueError, IndexError) as e:
            # print(f"âš ï¸ {code} ì¢…ëª© ì‹œì„¸ í¬ë¡¤ë§ ì˜¤ë¥˜ (í˜ì´ì§€ {page}): {e}") # ë””ë²„ê¹…ìš©
            break # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ ì¢…ëª©ì˜ ì‹œì„¸ í¬ë¡¤ë§ ì¤‘ë‹¨

    if dfs_sise:
        df_sise = pd.concat(dfs_sise, ignore_index=True)
        # ì¤‘ë³µëœ ë‚ ì§œ ì œê±° (í˜ì´ì§€ê°€ ê²¹ì³ì„œ ê°™ì€ ë‚ ì§œê°€ ì—¬ëŸ¬ë²ˆ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ)
        df_sise = df_sise.drop_duplicates(subset=['ë‚ ì§œ']).sort_values(by='ë‚ ì§œ')
        close_prices = df_sise['ì¢…ê°€'].astype(float).tail(days)
        volumes = df_sise['ê±°ë˜ëŸ‰'].astype(float).tail(days)
    
    return close_prices, volumes


# âœ… ì‹œì¥ë³„ ì£¼ì‹ ëª©ë¡ ë° ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ (ì™¸êµ­ì¸ë¹„ìœ¨ ì»¬ëŸ¼ ì¶”ê°€)
def fetch_stock_list(market='kospi', pages=10):
    base_url = {
        'kospi': 'https://finance.naver.com/sise/sise_market_sum.nhn?sosok=0&page=',
        'kosdaq': 'https://finance.naver.com/sise/sise_market_sum.nhn?sosok=1&page='
    }[market]

    # â­ ìµœì‹  User-Agentë¡œ ì—…ë°ì´íŠ¸
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    }
    dfs = []
    required_cols = ['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'PER', 'ROE'] # í•„ìˆ˜ ì»¬ëŸ¼
    foreign_rate_col_candidates = ['ì™¸êµ­ì¸ë¹„ìœ¨', 'ì™¸êµ­ì¸ë¹„ìœ¨(%)', 'ì™¸êµ­ì¸ë³´ìœ ìœ¨'] # ì™¸êµ­ì¸ ë¹„ìœ¨ ì»¬ëŸ¼ í›„ë³´ë“¤

    for page in range(1, pages + 1):
        url = base_url + str(page)
        print(f"--- ğŸŒ {market.upper()} í˜ì´ì§€ {page} í¬ë¡¤ë§ ì‹œë„ ì¤‘ ---")
        try:
            res = requests.get(url, headers=headers, timeout=15)
            if res.status_code != 200:
                print(f"âš ï¸ í˜ì´ì§€ {page} ì ‘ì† ì‹¤íŒ¨: Status Code {res.status_code}")
                continue
            
            # â­ ìº¡ì°¨/ì°¨ë‹¨ ê°ì§€
            if "ìº¡ì°¨" in res.text or "ì°¨ë‹¨" in res.text or "bot_block" in res.text:
                print(f"âŒ ê²½ê³ : {market.upper()} ì‹œì¥ í¬ë¡¤ë§ ì¤‘ ìº¡ì°¨/IP ì°¨ë‹¨ ê°ì§€. í˜ì´ì§€: {page}. í¬ë¡¤ë§ ì¤‘ë‹¨.")
                break # ì°¨ë‹¨ ê°ì§€ ì‹œ ë£¨í”„ ì¢…ë£Œ

            soup = BeautifulSoup(res.text, "html.parser")
            table_selector = "table.type_2"
            table = soup.select_one(table_selector) # CSS ì…€ë ‰í„°ë¡œ í…Œì´ë¸” ìš”ì†Œ ì§ì ‘ ì°¾ê¸°

            if not table: # í…Œì´ë¸” ìš”ì†Œ ìì²´ë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤ë©´
                print(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ '{table_selector}' í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (HTML êµ¬ì¡° ë³€ê²½ ë˜ëŠ” ë¹ˆ í˜ì´ì§€)")
                continue # ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°

            # â­ BeautifulSoupë¡œ ì°¾ì€ í…Œì´ë¸”ì˜ HTMLì„ StringIOë¡œ ì „ë‹¬
            # pd.read_htmlì€ í…Œì´ë¸” íƒœê·¸ ë‚´ë¶€ì˜ ë‚´ìš©ì„ ì½ë„ë¡ ìˆ˜ì •
            tables_from_html = pd.read_html(StringIO(str(table))) # ì°¾ì€ í…Œì´ë¸”ë§Œ íŒŒì‹±í•˜ë„ë¡ ë³€ê²½
            
            df_page = pd.DataFrame()
            found_target_table = False

            for temp_df in tables_from_html:
                # pandas_html_parserê°€ ê°€ë” í…Œì´ë¸” ì™¸ì˜ ë‹¤ë¥¸ ê²ƒì„ ì½ì–´ì˜¬ ìˆ˜ ìˆì–´ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° í•„í„°ë§ ê°•í™”
                if temp_df.empty or len(temp_df.columns) == 0:
                    continue

                # 'ì¢…ëª©ëª…' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìœ íš¨í•œ ì£¼ì‹ ëª©ë¡ í…Œì´ë¸”ì´ ì•„ë‹ˆë¼ê³  íŒë‹¨
                if 'ì¢…ëª©ëª…' not in temp_df.columns:
                    continue

                has_all_required_base_cols = all(col in temp_df.columns for col in required_cols)
                has_foreign_rate_col = any(col in temp_df.columns for col in foreign_rate_col_candidates)
                
                if has_all_required_base_cols and has_foreign_rate_col:
                    df_page = temp_df
                    found_target_table = True
                    break
            
            if not found_target_table:
                print(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ í•„ìˆ˜ ì»¬ëŸ¼ì„ í¬í•¨í•˜ëŠ” í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„° ë¶€ì¡± ë˜ëŠ” êµ¬ì¡° ë¯¸ìŠ¤ë§¤ì¹˜)")
                continue 

            foreign_rate_col_name_found = None
            for col_candidate in foreign_rate_col_candidates:
                if col_candidate in df_page.columns:
                    foreign_rate_col_name_found = col_candidate
                    break
            
            if not foreign_rate_col_name_found:
                # ì´ ê²½ìš°ëŠ” ìƒìœ„ if not found_target_table ì—ì„œ ì´ë¯¸ ê±¸ëŸ¬ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                print(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ ì™¸êµ­ì¸ë¹„ìœ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue 

            df_page = df_page.rename(columns={foreign_rate_col_name_found: 'ì™¸êµ­ì¸ë¹„ìœ¨'})
            
            final_cols = required_cols + ['ì™¸êµ­ì¸ë¹„ìœ¨']

            if not all(col in df_page.columns for col in final_cols):
                missing_cols = [col for col in final_cols if col not in df_page.columns]
                print(f"âš ï¸ í˜ì´ì§€ {page} - ìµœì¢… ì»¬ëŸ¼ ì„ íƒ í›„ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_cols}. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            df_page = df_page[final_cols].copy() 

            df_page['í˜„ì¬ê°€'] = df_page['í˜„ì¬ê°€'].apply(safe_float)
            df_page['PER'] = df_page['PER'].apply(safe_float)
            df_page['ROE'] = df_page['ROE'].apply(safe_float)
            df_page['ì™¸êµ­ì¸ë¹„ìœ¨'] = df_page['ì™¸êµ­ì¸ë¹„ìœ¨'].apply(safe_float)

            df_page = df_page.dropna(subset=final_cols) # í•„ìˆ˜ ì»¬ëŸ¼ ì¤‘ NaN ìˆëŠ” í–‰ ì œê±°
            
            df_page['í˜„ì¬ê°€'] = df_page['í˜„ì¬ê°€'].astype(int)

            if df_page.empty:
                print(f"âš ï¸ í˜ì´ì§€ {page} - NaN ê°’ ì œê±° í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            dfs.append(df_page)
            print(f"âœ… í˜ì´ì§€ {page}ì—ì„œ {len(df_page)}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ.")
            
            time.sleep(0.5) # í˜ì´ì§€ ìš”ì²­ ê°„ ë”œë ˆì´ ì¶”ê°€ (IP ì°¨ë‹¨ ë°©ì§€)

        except (requests.exceptions.RequestException, ValueError, IndexError, KeyError, TypeError) as e:
            print(f"âŒ ì‹œì¥ ëª©ë¡ í¬ë¡¤ë§ ì˜¤ë¥˜ (í˜ì´ì§€ {page}, ìƒì„¸: {e})")
            continue 

    if not dfs:
        print("âŒ ì‹œì¥ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¹ˆ DataFrame ë°˜í™˜.")
        return pd.DataFrame()

    full_df = pd.concat(dfs, ignore_index=True)
    full_df = full_df.dropna(subset=required_cols + ['ì™¸êµ­ì¸ë¹„ìœ¨']) 
    
    return full_df.reset_index(drop=True)


# ê° ì¢…ëª©ì„ ì²˜ë¦¬í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def _process_single_stock(stock_info, code_map):
    name = stock_info['ì¢…ëª©ëª…']
    code = code_map.get(name)
    if not code:
        return None

    try:
        close_prices, volumes = fetch_real_close_prices(code) 
        
        current_foreign_rate = stock_info.get('ì™¸êµ­ì¸ë¹„ìœ¨', np.nan) 
        
        if len(close_prices) < 60 or len(volumes) < 60: 
            return None

        rsi_series = ta.rsi(close_prices, length=14)
        macd_df = ta.macd(close_prices)
        bb_df = ta.bbands(close_prices)

        if rsi_series.empty or macd_df.empty or bb_df.empty:
             return None

        current_rsi = rsi_series.iloc[-1]
        prev_rsi = rsi_series.iloc[-2] if len(rsi_series) >= 2 else np.nan
        macd_line = macd_df["MACD_12_26_9"].iloc[-1]
        signal_line = macd_df["MACDs_12_26_9"].iloc[-1]
        prev_macd_line = macd_df["MACD_12_26_9"].iloc[-2] if len(macd_df) >= 2 else np.nan
        prev_signal_line = macd_df["MACDs_12_26_9"].iloc[-2] if len(macd_df) >= 2 else np.nan
        percent_b = bb_df["BBP_5_2.0"].iloc[-1]
        bbl = bb_df["BBL_5_2.0"].iloc[-1]
        bbm = bb_df["BBM_5_2.0"].iloc[-1] # ë³¼ë¦°ì €ë°´ë“œ ì¤‘ê°„ì„  (20ì¼ ì´í‰ì„ )
        current_close_price = close_prices.iloc[-1]
        current_volume = volumes.iloc[-1]
        
        avg_volume_20_days = volumes.rolling(window=20).mean().iloc[-1] if len(volumes) >= 20 else np.nan

        foreign_ownership_change = np.nan 
        
        is_foreign_inflow = True if pd.notna(current_foreign_rate) and current_foreign_rate >= 5 else False 

        per = stock_info["PER"] if pd.notna(stock_info["PER"]) and stock_info["PER"] > 0 else 1000
        roe = stock_info["ROE"] if pd.notna(stock_info["ROE"]) else 0

        # --- â­ ê¸‰ë“±_ì ìˆ˜ 10ì  ë§Œì  ì„¸ë¶„í™” ë¡œì§ ì‹œì‘ â­ ---
        surge_score = 0
        temp_surge_signals = [] # ì¤‘ë³µ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì„ì‹œ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©

        # 1. RSI ì ìˆ˜ (ìµœëŒ€ 2.5ì )
        is_rsi_recovery = False
        if pd.notna(prev_rsi) and prev_rsi < 30 and current_rsi >= 30:
            is_rsi_recovery = True
            surge_score += 1.0 # RSI íšŒë³µ ê¸°ë³¸ ì ìˆ˜
            
            if current_rsi >= 50:
                surge_score += 1.0 # RSI 50+ ëŒíŒŒ
                temp_surge_signals.append("RSI 50+ ëŒíŒŒ")
            
            if prev_rsi < 20: # ë” ê¹Šì€ ê³¼ë§¤ë„ì—ì„œ íšŒë³µ
                surge_score += 0.5
                temp_surge_signals.append("RSI ê¹Šì€ ê³¼ë§¤ë„ íšŒë³µ")
            
            if not ("RSI 50+ ëŒíŒŒ" in temp_surge_signals or "RSI ê¹Šì€ ê³¼ë§¤ë„ íšŒë³µ" in temp_surge_signals):
                temp_surge_signals.append("RSI íšŒë³µ")


        # 2. MACD ì ìˆ˜ (ìµœëŒ€ 2.5ì )
        is_macd_golden_cross = False
        if pd.notna(prev_macd_line) and pd.notna(prev_signal_line) and \
           macd_line > signal_line and prev_macd_line <= prev_signal_line:
            is_macd_golden_cross = True
            surge_score += 1.0 # MACD ê³¨ë“  í¬ë¡œìŠ¤ ê¸°ë³¸ ì ìˆ˜
            
            if macd_line > 0 and prev_macd_line <= 0: # MACD 0ì„  ëŒíŒŒ
                surge_score += 1.0
                temp_surge_signals.append("MACD GC & 0ì„  ëŒíŒŒ")
            
            macd_diff = macd_line - signal_line
            if macd_diff > 0.5: # MACD ì´ê²© í™•ëŒ€ (ìƒìŠ¹ ê°•ë„)
                surge_score += 0.5
                if "MACD GC & 0ì„  ëŒíŒŒ" not in temp_surge_signals:
                    temp_surge_signals.append("MACD ì´ê²© í™•ëŒ€")
            
            if not ("MACD GC & 0ì„  ëŒíŒŒ" in temp_surge_signals or "MACD ì´ê²© í™•ëŒ€" in temp_surge_signals):
                temp_surge_signals.append("MACD GC")


        # 3. ë³¼ë¦°ì €ë°´ë“œ ì ìˆ˜ (ìµœëŒ€ 2ì )
        is_bb_lower_band_recovery = False
        if len(close_prices) >= 10 and not bb_df["BBL_5_2.0"].iloc[-10:].isnull().any():
            was_below_bbl = any(close_prices.iloc[-10:-1] < bb_df["BBL_5_2.0"].iloc[-10:-1])
            is_above_bbl_now = current_close_price > bbl
            if was_below_bbl and is_above_bbl_now:
                is_bb_lower_band_recovery = True
                surge_score += 1.0 # BB í•˜ë‹¨ íšŒë³µ ê¸°ë³¸ ì ìˆ˜

                if current_close_price > bbm and close_prices.iloc[-2] <= bbm: # BB ì¤‘ê°„ì„  ëŒíŒŒ
                    surge_score += 0.5
                    temp_surge_signals.append("BB í•˜ë‹¨ & ì¤‘ê°„ì„  ëŒíŒŒ")
                
                bb_width = bb_df["BBU_5_2.0"].iloc[-1] - bb_df["BBL_5_2.0"].iloc[-1]
                prev_bb_width = bb_df["BBU_5_2.0"].iloc[-2] - bb_df["BBL_5_2.0"].iloc[-2] if len(bb_df) >= 2 else np.nan
                if pd.notna(prev_bb_width) and prev_bb_width > 0 and bb_width < prev_bb_width * 0.9: # BB ìˆ˜ë ´ í›„ íšŒë³µ
                    surge_score += 0.5
                    if "BB í•˜ë‹¨ & ì¤‘ê°„ì„  ëŒíŒŒ" not in temp_surge_signals:
                        temp_surge_signals.append("BB ìˆ˜ë ´ í›„ íšŒë³µ")
                
                if not ("BB í•˜ë‹¨ & ì¤‘ê°„ì„  ëŒíŒŒ" in temp_surge_signals or "BB ìˆ˜ë ´ í›„ íšŒë³µ" in temp_surge_signals):
                    temp_surge_signals.append("BB í•˜ë‹¨ íšŒë³µ")


        # 4. ê±°ë˜ëŸ‰ ì ìˆ˜ (ìµœëŒ€ 2.5ì )
        is_volume_spike = False
        if pd.notna(avg_volume_20_days) and avg_volume_20_days > 0 and current_volume > (avg_volume_20_days * 2):
            is_volume_spike = True
            
            volume_signal_score = 0
            if current_volume > (avg_volume_20_days * 10):
                volume_signal_score += 1.5
                temp_surge_signals.append("ê±°ë˜ëŸ‰ 10ë°°+ ê¸‰ì¦")
            elif current_volume > (avg_volume_20_days * 5):
                volume_signal_score += 1.0
                temp_surge_signals.append("ê±°ë˜ëŸ‰ 5ë°°+ ê¸‰ì¦")
            elif current_volume > (avg_volume_20_days * 2):
                volume_signal_score += 0.5
                temp_surge_signals.append("ê±°ë˜ëŸ‰ 2ë°°+ ê¸‰ì¦")
            
            surge_score += volume_signal_score # ê¸°ë³¸ ê¸‰ì¦ ì ìˆ˜

            if len(close_prices) >= 5: # ìƒìŠ¹ ì¶”ì„¸ì—ì„œ ê±°ë˜ëŸ‰ ê¸‰ì¦
                ma_5 = close_prices.rolling(window=5).mean().iloc[-1]
                prev_ma_5 = close_prices.rolling(window=5).mean().iloc[-2] if len(close_prices) >= 5 else np.nan
                if current_close_price > ma_5 and pd.notna(prev_ma_5) and ma_5 > prev_ma_5:
                    surge_score += 1.0 # 0.5ì ì—ì„œ 1ì ìœ¼ë¡œ ìƒí–¥
                    temp_surge_signals.append("ìƒìŠ¹ ì¶”ì„¸ ê±°ë˜ëŸ‰")
        
        # 5. ì™¸êµ­ì¸ ìˆ˜ê¸‰ ì ìˆ˜ (ìµœëŒ€ 1.5ì )
        is_foreign_high_ownership = False
        if pd.notna(current_foreign_rate) and current_foreign_rate >= 5:
            is_foreign_high_ownership = True
            surge_score += 0.5 # ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 5% ì´ìƒ ê¸°ë³¸ ì ìˆ˜
            
            if current_foreign_rate >= 10:
                surge_score += 0.5 # ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 10% ì´ìƒ ì¶”ê°€ ì ìˆ˜
                temp_surge_signals.append("ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 10%+ ë†’ì€")
            
            if current_foreign_rate >= 20:
                surge_score += 0.5 # ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 20% ì´ìƒ ì¶”ê°€ ì ìˆ˜
                temp_surge_signals.append("ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 20%+ ë†’ì€")
            
            if not ("ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 10%+ ë†’ì€" in temp_surge_signals or "ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 20%+ ë†’ì€" in temp_surge_signals):
                temp_surge_signals.append("ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 5%+ ë†’ì€")


        # ê¸‰ë“± ì‹œê·¸ë„ í…ìŠ¤íŠ¸ ì •ë¦¬ (ìµœì¢…ì ìœ¼ë¡œ ìœ ì¼í•œ ì‹œê·¸ë„ë§Œ ë‚¨ê¸°ê¸°)
        surge_signals_final = []
        
        # RSI ì‹œê·¸ë„ ì²˜ë¦¬ (ê°€ì¥ ê°•í•œ ì‹œê·¸ë„ í•˜ë‚˜ë§Œ)
        if "RSI ê¹Šì€ ê³¼ë§¤ë„ íšŒë³µ" in temp_surge_signals:
            surge_signals_final.append("RSI ê¹Šì€ ê³¼ë§¤ë„ íšŒë³µ")
        elif "RSI 50+ ëŒíŒŒ" in temp_surge_signals:
            surge_signals_final.append("RSI 50+ ëŒíŒŒ")
        elif "RSI íšŒë³µ" in temp_surge_signals:
            surge_signals_final.append("RSI íšŒë³µ")

        # MACD ì‹œê·¸ë„ ì²˜ë¦¬ (ê°€ì¥ ê°•í•œ ì‹œê·¸ë„ í•˜ë‚˜ë§Œ)
        if "MACD GC & 0ì„  ëŒíŒŒ" in temp_surge_signals:
            surge_signals_final.append("MACD GC & 0ì„  ëŒíŒŒ")
        elif "MACD ì´ê²© í™•ëŒ€" in temp_surge_signals:
            surge_signals_final.append("MACD ì´ê²© í™•ëŒ€")
        elif "MACD GC" in temp_surge_signals:
            surge_signals_final.append("MACD GC")

        # BB ì‹œê·¸ë„ ì²˜ë¦¬ (ê°€ì¥ ê°•í•œ ì‹œê·¸ë„ í•˜ë‚˜ë§Œ)
        if "BB í•˜ë‹¨ & ì¤‘ê°„ì„  ëŒíŒŒ" in temp_surge_signals:
            surge_signals_final.append("BB í•˜ë‹¨ & ì¤‘ê°„ì„  ëŒíŒŒ")
        elif "BB ìˆ˜ë ´ í›„ íšŒë³µ" in temp_surge_signals:
            surge_signals_final.append("BB ìˆ˜ë ´ í›„ íšŒë³µ")
        elif "BB í•˜ë‹¨ íšŒë³µ" in temp_surge_signals:
            surge_signals_final.append("BB í•˜ë‹¨ íšŒë³µ")

        # ê±°ë˜ëŸ‰ ì‹œê·¸ë„ ì²˜ë¦¬ (ê°€ì¥ ê°•í•œ ì‹œê·¸ë„ í•˜ë‚˜ + ìƒìŠ¹ ì¶”ì„¸)
        volume_signal_text = ""
        if "ê±°ë˜ëŸ‰ 10ë°°+ ê¸‰ì¦" in temp_surge_signals:
            volume_signal_text = "ê±°ë˜ëŸ‰ 10ë°°+ ê¸‰ì¦"
        elif "ê±°ë˜ëŸ‰ 5ë°°+ ê¸‰ì¦" in temp_surge_signals:
            volume_signal_text = "ê±°ë˜ëŸ‰ 5ë°°+ ê¸‰ì¦"
        elif "ê±°ë˜ëŸ‰ 2ë°°+ ê¸‰ì¦" in temp_surge_signals:
            volume_signal_text = "ê±°ë˜ëŸ‰ 2ë°°+ ê¸‰ì¦"
        
        if volume_signal_text:
            if "ìƒìŠ¹ ì¶”ì„¸ ê±°ë˜ëŸ‰" in temp_surge_signals:
                surge_signals_final.append(f"ìƒìŠ¹ ì¶”ì„¸ {volume_signal_text}")
            else:
                surge_signals_final.append(volume_signal_text)

        # ì™¸êµ­ì¸ ìˆ˜ê¸‰ ì‹œê·¸ë„ ì²˜ë¦¬ (ê°€ì¥ ê°•í•œ ì‹œê·¸ë„ í•˜ë‚˜ë§Œ)
        if "ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 20%+ ë†’ì€" in temp_surge_signals:
            surge_signals_final.append("ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 20%+ ë†’ì€")
        elif "ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 10%+ ë†’ì€" in temp_surge_signals:
            surge_signals_final.append("ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 10%+ ë†’ì€")
        elif "ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 5%+ ë†’ì€" in temp_surge_signals:
            surge_signals_final.append("ì™¸êµ­ì¸ ë³´ìœ ìœ¨ 5%+ ë†’ì€")

        surge_signal_text = ", ".join(surge_signals_final) if surge_signals_final else "ì—†ìŒ"
        
        # --- â­ ê¸‰ë“±_ì ìˆ˜ 10ì  ë§Œì  ì„¸ë¶„í™” ë¡œì§ ë â­ ---


        # â­ ì´ ê¸‰ë“± ì ìˆ˜ê°€ 10ì ì„ ë„˜ì§€ ì•Šë„ë¡ ìƒí•œ ì ìš© (ì„ íƒ ì‚¬í•­)
        # í˜„ì¬ ë°°ì ìœ¼ë¡œëŠ” 10ì  ì´ˆê³¼ê°€ ê°€ëŠ¥í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœëŒ€ 10ì ìœ¼ë¡œ ì œí•œí•˜ëŠ” ë¡œì§ ì¶”ê°€
        surge_score = min(surge_score, 10.0)


        per_score = min(1/per * 100, 1)
        roe_score = roe / 20
        rsi_score_for_rank = 1 if current_rsi < 30 else 0 if current_rsi > 70 else 0.5 # ê¸°ì¡´ ë­í¬ ì ìˆ˜ìš© RSI
        macd_score_for_rank = 1 if is_macd_golden_cross else 0 # ê¸°ì¡´ ë­í¬ ì ìˆ˜ìš© MACD
        bb_score_for_rank = percent_b # ê¸°ì¡´ ë­í¬ ì ìˆ˜ìš© BB
        foreign_score_for_rank = 1 if is_foreign_high_ownership else 0 # ê¸°ì¡´ ë­í¬ ì ìˆ˜ìš© ì™¸êµ­ì¸ ìˆ˜ê¸‰

        raw_metrics = [per_score, roe_score, rsi_score_for_rank, macd_score_for_rank, bb_score_for_rank, foreign_score_for_rank]

        naver_stock_link = f"https://finance.naver.com/item/main.naver?code={code}"

        estimated_return = np.nan # ê¸°ë³¸ê°’ì€ NaN
        target_per = 15.0 # â­ ì˜ˆì‹œ: ëª©í‘œ PER (ì‚°ì—… í‰ê·  PER ë“±ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥)
        
        if pd.notna(per) and per > 0: # PERì´ ìœ íš¨í•œ ê°’ì¼ ë•Œë§Œ ê³„ì‚°
            # PERì´ ë„ˆë¬´ ë†’ê±°ë‚˜ ë„ˆë¬´ ë‚®ì€ ê·¹ë‹¨ì ì¸ ê°’ì¼ ê²½ìš° í•„í„°ë§ (ì˜ˆ: PER 500 ì´ìƒì€ ì œì™¸)
            if per < 500: # 500ë°° ì´ìƒì˜ PERì€ ì˜ë¯¸ê°€ ì—†ì„ ìˆ˜ ìˆì–´ì„œ í•„í„°ë§
                estimated_return = ((target_per / per) - 1) * 100
                estimated_return = round(estimated_return, 2)
            else:
                estimated_return = -100.0 # PERì´ ë„ˆë¬´ ë†’ìœ¼ë©´ í° í­ì˜ ë§ˆì´ë„ˆìŠ¤ ìˆ˜ìµë¥ ë¡œ í‘œì‹œ
        
        # PERì´ 0ì— ê°€ê¹ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš° (ì ì ê¸°ì—… ë“±) ì²˜ë¦¬
        if per <= 0:
            estimated_return = -999.99 # PERì´ 0ì´ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš° ë§¤ìš° ë‚®ì€ ìˆ˜ìµë¥ ë¡œ í‘œì‹œ

        return {
            "ì¢…ëª©ëª…": name,
            "í˜„ì¬ê°€": stock_info["í˜„ì¬ê°€"],
            "PER": round(per, 2),
            "ROE": round(roe, 2),
            "RSI": round(current_rsi, 2) if pd.notna(current_rsi) else np.nan,
            "MACD_Line": round(macd_line, 2),
            "Signal_Line": round(signal_line, 2),
            "BB_Percent_B": round(percent_b, 2),
            "í˜„ì¬_ê±°ë˜ëŸ‰": int(current_volume) if pd.notna(current_volume) else 0,
            "20ì¼_í‰ê· _ê±°ë˜ëŸ‰": int(avg_volume_20_days) if pd.notna(avg_volume_20_days) else 0,
            "ì™¸êµ­ì¸_í˜„ì¬_ë³´ìœ ìœ¨": round(current_foreign_rate, 2) if pd.notna(current_foreign_rate) else np.nan,
            "ì™¸êµ­ì¸_ë³´ìœ ìœ¨_ë³€í™”": np.nan, 
            "ê¸‰ë“±_ì ìˆ˜": round(surge_score, 2), # â­ ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
            "ê¸‰ë“±_ì‹œê·¸ë„": surge_signal_text,
            "ë„¤ì´ë²„_ì£¼ì‹_ë§í¬": naver_stock_link,
            "ì˜ˆìƒ_ìˆ˜ìµë¥ ": estimated_return,
            "_raw_metrics": raw_metrics
        }

    except Exception as e:
        print(f"âš ï¸ ì¢…ëª© '{name}' (ì½”ë“œ: {code}) ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# âœ… ì¢…ëª© ì ìˆ˜ ê³„ì‚° ë° ê¸‰ë“± í•„í„° í¬í•¨ (ë³‘ë ¬ ì²˜ë¦¬ ì ìš©)
def rank_stocks(df, code_map):
    all_stock_data = []
    
    max_workers = os.cpu_count() * 2 if os.cpu_count() else 10

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(_process_single_stock, row.to_dict(), code_map): row['ì¢…ëª©ëª…'] for idx, row in df.iterrows()}
        
        processed_count = 0
        total_stocks = len(futures)

        for future in concurrent.futures.as_completed(futures):
            processed_count += 1
            stock_name = futures[future]
            try:
                result = future.result()
                if result:
                    all_stock_data.append(result)
            except Exception as exc:
                print(f"âš ï¸ ì¢…ëª© '{stock_name}' ìµœì¢… ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {exc}")
            
            if processed_count % 100 == 0 or processed_count == total_stocks:
                print(f"  {processed_count}/{total_stocks} ì¢…ëª© ì²˜ë¦¬ ì™„ë£Œ ({stock_name} ì²˜ë¦¬ë¨)")

    if not all_stock_data:
        print("âŒ rank_stocks: ìœ íš¨í•œ ë°ì´í„°ë¥¼ ê°€ì§„ ì¢…ëª©ì´ ì—†ì–´ ìµœì¢… DataFrameì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. JSON íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    try:
        metrics_array = np.array([item["_raw_metrics"] for item in all_stock_data])
        scaler = MinMaxScaler()
        normed = scaler.fit_transform(metrics_array)
        
        weights = np.array([0.2, 0.2, 0.15, 0.15, 0.1, 0.2])
        final_scores = normed @ weights

        for i, score in enumerate(final_scores):
            all_stock_data[i]['score'] = round(score, 4)
            del all_stock_data[i]['_raw_metrics']
    except Exception as e:
        print(f"âŒ ì ìˆ˜ ì •ê·œí™” ë° ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()


    full_df = pd.DataFrame(all_stock_data).sort_values(by="score", ascending=False).reset_index(drop=True)

    financial_df = full_df[
        (full_df['PER'] < 30) & (full_df['ROE'] > 5)
    ].sort_values(by=["ROE", "PER", "score"], ascending=[False, True, False]).head(50)

    # â­ ê¸‰ë“± ì ìˆ˜ í•„í„°ë§ ì œê±° ë° ì •ë ¬ë§Œ ì ìš©
    surge_df = full_df.sort_values(by="ê¸‰ë“±_ì ìˆ˜", ascending=False).reset_index(drop=True)

    return full_df, financial_df, surge_df


# âœ… ì‹œì¥ë³„ ì‹¤í–‰
def run_for_market(market):
    print(f"\n--- ğŸ“Š {market.upper()} ì‹œì¥ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘ ---")
    start_time = time.time()
    
    # â­ í˜ì´ì§€ ìˆ˜ë¥¼ 5ë¡œ ì¼ë‹¨ ì¤„ì—¬ì„œ í…ŒìŠ¤íŠ¸í•´ë³´ì.
    df = fetch_stock_list(market, pages=5) 
    print(f"âœ… {len(df)}ê°œ ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ.")
    if df.empty:
        print(f"âš ï¸ {market.upper()} ì‹œì¥ì— ìœ íš¨í•œ ì¢…ëª©ì´ ì—†ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print("ğŸ—ºï¸ ì¢…ëª© ì½”ë“œ ë§¤í•‘ ì¤‘...")
    code_map = fetch_code_map()
    if not code_map:
        print(f"âš ï¸ ì¢…ëª© ì½”ë“œ ë§¤í•‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print("â³ ì¢…ëª© ì ìˆ˜ ê³„ì‚° ì¤‘ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥´ê²Œ ì§„í–‰ë©ë‹ˆë‹¤)...")
    full, financial, surge = rank_stocks(df, code_map)

    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"\nâœ¨ {market.upper()} ì‹œì¥ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ! (ì´ {elapsed_time:.2f}ì´ˆ ì†Œìš”)")

    print(f"\n--- ğŸ† {market.upper()} ì „ì²´ ìƒìœ„ ì¢…í•© ë­í‚¹ ---")
    print(full[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'score', 'ì˜ˆìƒ_ìˆ˜ìµë¥ ', 'ë„¤ì´ë²„_ì£¼ì‹_ë§í¬']].head(20) if not full.empty else "ì—†ìŒ")

    print(f"\n--- ğŸ’° {market.upper()} ì¬ë¬´ ê±´ì „ì„± ìš°ìˆ˜ ì¢…ëª© (PER 30 ì´í•˜, ROE 5 ì´ìƒ ê¸°ì¤€) ---")
    print(financial[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'PER', 'ROE', 'ì˜ˆìƒ_ìˆ˜ìµë¥ ', 'score', 'ë„¤ì´ë²„_ì£¼ì‹_ë§í¬']].head(20) if not financial.empty else "ì—†ìŒ")

    print(f"\n--- ğŸ”¥ {market.upper()} ê¸‰ë“± ê°€ëŠ¥ì„± ì¢…ëª© (ê¸‰ë“± ì ìˆ˜ ìˆœ) ---") # ì¶œë ¥ ë¬¸êµ¬ ë³€ê²½
    # â­ ê¸‰ë“± ì ìˆ˜ ìƒìœ„ 20ê°œ ì¢…ëª© ì¶œë ¥
    print(surge[['ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ê¸‰ë“±_ì ìˆ˜', 'ê¸‰ë“±_ì‹œê·¸ë„', 'í˜„ì¬_ê±°ë˜ëŸ‰', '20ì¼_í‰ê· _ê±°ë˜ëŸ‰', 'ì™¸êµ­ì¸_í˜„ì¬_ë³´ìœ ìœ¨', 'ì˜ˆìƒ_ìˆ˜ìµë¥ ', 'score', 'ë„¤ì´ë²„_ì£¼ì‹_ë§í¬']].head(20) if not surge.empty else "ì—†ìŒ") 

    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)

    if not full.empty:
        full.to_json(f"{output_dir}/{market}_ranked_stocks_all.json", orient="records", force_ascii=False, indent=2)
        print(f"\nğŸ“ {output_dir}/{market}_ranked_stocks_all.json ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âš ï¸ {market.upper()} ì „ì²´ ë­í‚¹ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ JSON íŒŒì¼ ì €ì¥ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    if not financial.empty:
        financial.to_json(f"{output_dir}/{market}_ranked_stocks_financial_healthy.json", orient="records", force_ascii=False, indent=2)
        print(f"ğŸ“ {output_dir}/{market}_ranked_stocks_financial_healthy.json ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âš ï¸ {market.upper()} ì¬ë¬´ ê±´ì „ì„± ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ JSON íŒŒì¼ ì €ì¥ ê±´ë„ˆí‚µë‹ˆë‹¤.")

    if not surge.empty:
        # â­ ê¸‰ë“± ì ìˆ˜ í•„í„°ë§ì„ ì—†ì•´ìœ¼ë‹ˆ, íŒŒì¼ëª…ë„ í•„í„° ê¸°ì¤€ì´ ì—†ë‹¤ëŠ” ê²ƒì„ ë°˜ì˜ (potential_surge ìœ ì§€ ê°€ëŠ¥)
        surge.to_json(f"{output_dir}/{market}_ranked_stocks_potential_surge.json", orient="records", force_ascii=False, indent=2)
        print(f"ğŸ“ {output_dir}/{market}_ranked_stocks_potential_surge.json ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âš ï¸ {market.upper()} ê¸‰ë“± ê°€ëŠ¥ì„± ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ JSON íŒŒì¼ ì €ì¥ ê±´ë„ˆí‚µë‹ˆë‹¤.")
    
    print(f"\n--- {market.upper()} ì‹œì¥ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ---\n")


# âœ… ì‹¤í–‰
if __name__ == "__main__":
    run_for_market("kospi")
    run_for_market("kosdaq")